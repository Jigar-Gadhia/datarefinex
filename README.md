# ğŸ“Š DataRefineX v1 â€” Intelligent CSV Cleaning & Processing Pipeline

DataRefineX is a **production-ready CSV processing system** built using FastAPI, Celery, Redis, Streamlit, Docker, and HuggingFace Hub.  
It can clean huge CSV files, remove corrupted data, fix encoding issues, deduplicate rows, and upload cleaned data to a HuggingFace dataset automatically.

---

## ğŸš€ Features

### ğŸ”¹ CSV Cleaning Engine
- Auto-detect encoding using `chardet`
- Remove null bytes
- Chunked processing for large files (50k rows per batch)
- Auto-skip bad lines
- Deduplication
- Clean output saved as `cleaned_data.csv`

### ğŸ”¹ Background Processing with Celery
- Async job queue
- Runs independently from API
- Redis-backed broker & result store
- Track job status via FastAPI

### ğŸ”¹ Upload Cleaned Data to HuggingFace
- Uses HuggingFace Hub API
- Uploads cleaned CSV to dataset repository

### ğŸ”¹ Streamlit Frontend Dashboard
- Enter CSV URL
- Submit processing job
- Real-time progress bar
- See cleaned output + HuggingFace link

### ğŸ”¹ Fully Dockerized
- FastAPI API (`Dockerfile.api`)
- Celery Worker (`Dockerfile.worker`)
- Redis service
- Easy Compose orchestration

### ğŸ”¹ Pipenv for Dependency Management
- Clean reproducible Python environment

---

## ğŸ— Architecture
- Streamlit UI â†’ FastAPI â†’ Celery Worker â†’ Redis â†’ HuggingFace Hub

---


---

## âš™ï¸ Environment Variables (`.env`)

```
broker_uri=redis://redis:6379/0
backend_uri=redis://redis:6379/0
token=YOUR_HUGGINGFACE_TOKEN
hf_repo=username/dataset-name
```

---

## ğŸ³ Install Docker (Required)

DataRefineX uses Docker and Docker Compose to run all services (API, Worker, Redis).  
Before running the project, install Docker Desktop:

### **ğŸ”¹ Download Docker Desktop**
- **Windows / macOS:**  
  https://www.docker.com/products/docker-desktop/

- **Linux:**  
  Follow official installation docs:  
  https://docs.docker.com/engine/install/

### **ğŸ”¹ After installation**
Make sure Docker is running:

```
docker --version
```
```
docker compose version
```


## ğŸ³ Running with Docker Compose

### 1ï¸âƒ£ Start all services

```
docker compose up --build
```

---

### 2ï¸âƒ£ Available services

| Service   | URL                          |
|-----------|-------------------------------|
| FastAPI   | http://localhost:8000/docs    |
| Streamlit | http://localhost:8501         |
| Redis     | Internal container only        |

---

### 3ï¸âƒ£ Worker Logs

```
docker compose logs -f worker
```

## ğŸ–¥ Running Streamlit (Frontend)

```
streamlit run ui/app.py
```

---

## ğŸ›  Technology Stack

| Component        | Technology         |
|------------------|---------------------|
| Backend API      | FastAPI             |
| Background Jobs  | Celery              |
| Broker           | Redis               |
| Frontend UI      | Streamlit           |
| File Upload      | HuggingFace Hub     |
| Dependency Mgmt  | Pipenv              |
| Containers       | Docker + Compose    |

---

## â­ Future Improvements

- Add user authentication  
- Allow uploading local CSV files  
- Add job history  
- Email notifications  
- Distributed Celery workers  
- GPU processing for ML pipelines
- Github Actions support

---

## ğŸ¤ Contributing

Pull requests are welcome.  
For major changes, please open an issue first to discuss what you would like to change.

---

## ğŸ“œ License

MIT License.
